#!/usr/bin/env python3
"""
å‰ç½®ä»»åŠ¡çº¦æŸéªŒè¯å™¨
éªŒè¯æ±‚è§£ç»“æœä¸­çš„å‰ç½®ä»»åŠ¡çº¦æŸæ˜¯å¦æ­£ç¡®ç”Ÿæ•ˆ
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any


class DependencyConstraintValidator:
    """å‰ç½®ä»»åŠ¡çº¦æŸéªŒè¯å™¨"""
    
    def __init__(self, solution_file: str):
        self.solution_file = solution_file
        self.solution_data = None
        self.task_intervals = []
        self.task_lookup = {}
        
    def load_solution(self) -> bool:
        """åŠ è½½æ±‚è§£ç»“æœ"""
        try:
            with open(self.solution_file, 'r', encoding='utf-8') as f:
                self.solution_data = json.load(f)
            
            self.task_intervals = self.solution_data.get('schedule', {}).get('task_intervals', [])
            self.task_lookup = {task['task_id']: task for task in self.task_intervals}
            
            print(f"âœ… æˆåŠŸåŠ è½½æ±‚è§£ç»“æœ: {len(self.task_intervals)} ä¸ªä»»åŠ¡")
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ±‚è§£ç»“æœå¤±è´¥: {e}")
            return False
    
    def validate_predecessor_constraints(self) -> Dict[str, Any]:
        """éªŒè¯å‰ç½®ä»»åŠ¡çº¦æŸ"""
        print("\nğŸ” éªŒè¯å‰ç½®ä»»åŠ¡çº¦æŸ...")
        
        validation_results = {
            "total_tasks": len(self.task_intervals),
            "tasks_with_predecessors": 0,
            "constraint_violations": [],
            "constraint_satisfied": 0,
            "validation_passed": True
        }
        
        for task in self.task_intervals:
            task_id = task['task_id']
            predecessor_jobs = task.get('predecessor_jobs', [])
            
            if not predecessor_jobs:
                continue
                
            validation_results["tasks_with_predecessors"] += 1
            
            # è§£æä»»åŠ¡å¼€å§‹æ—¶é—´
            task_start_time = datetime.fromisoformat(task['start_time'])
            
            # æ£€æŸ¥æ¯ä¸ªå‰ç½®ä»»åŠ¡
            for pred_id in predecessor_jobs:
                if pred_id not in self.task_lookup:
                    violation = {
                        "task_id": task_id,
                        "violation_type": "missing_predecessor",
                        "predecessor_id": pred_id,
                        "description": f"å‰ç½®ä»»åŠ¡ {pred_id} ä¸å­˜åœ¨"
                    }
                    validation_results["constraint_violations"].append(violation)
                    validation_results["validation_passed"] = False
                    continue
                
                pred_task = self.task_lookup[pred_id]
                pred_end_time = datetime.fromisoformat(pred_task['end_time'])
                
                # æ£€æŸ¥æ—¶é—´çº¦æŸï¼šå‰ç½®ä»»åŠ¡å¿…é¡»åœ¨å½“å‰ä»»åŠ¡å¼€å§‹å‰å®Œæˆ
                if pred_end_time > task_start_time:
                    violation = {
                        "task_id": task_id,
                        "violation_type": "time_constraint_violation",
                        "predecessor_id": pred_id,
                        "task_start": task['start_time'],
                        "predecessor_end": pred_task['end_time'],
                        "description": f"å‰ç½®ä»»åŠ¡ {pred_id} åœ¨å½“å‰ä»»åŠ¡ {task_id} å¼€å§‹åæ‰å®Œæˆ"
                    }
                    validation_results["constraint_violations"].append(violation)
                    validation_results["validation_passed"] = False
                else:
                    validation_results["constraint_satisfied"] += 1
        
        return validation_results
    
    def analyze_dependency_structure(self) -> Dict[str, Any]:
        """åˆ†æä¾èµ–å…³ç³»ç»“æ„"""
        print("\nğŸ“Š åˆ†æä¾èµ–å…³ç³»ç»“æ„...")
        
        analysis = {
            "dependency_patterns": {},
            "critical_path_analysis": {},
            "complexity_metrics": {}
        }
        
        # ç»Ÿè®¡ä¾èµ–æ¨¡å¼
        dependency_counts = {}
        for task in self.task_intervals:
            pred_count = len(task.get('predecessor_jobs', []))
            dependency_counts[pred_count] = dependency_counts.get(pred_count, 0) + 1
        
        analysis["dependency_patterns"] = dependency_counts
        
        # å…³é”®è·¯å¾„åˆ†æ
        critical_tasks = [t for t in self.task_intervals if t.get('is_critical_path', False)]
        analysis["critical_path_analysis"] = {
            "total_critical_tasks": len(critical_tasks),
            "critical_task_ratio": len(critical_tasks) / len(self.task_intervals) if self.task_intervals else 0
        }
        
        # å¤æ‚åº¦æŒ‡æ ‡
        max_predecessors = max((len(t.get('predecessor_jobs', [])) for t in self.task_intervals), default=0)
        avg_predecessors = sum(len(t.get('predecessor_jobs', [])) for t in self.task_intervals) / len(self.task_intervals) if self.task_intervals else 0
        
        analysis["complexity_metrics"] = {
            "max_predecessors_per_task": max_predecessors,
            "average_predecessors_per_task": round(avg_predecessors, 2),
            "total_dependency_relationships": sum(len(t.get('predecessor_jobs', [])) for t in self.task_intervals)
        }
        
        return analysis
    
    def print_validation_report(self, validation_results: Dict[str, Any], analysis: Dict[str, Any]):
        """æ‰“å°éªŒè¯æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ å‰ç½®ä»»åŠ¡çº¦æŸéªŒè¯æŠ¥å‘Š")
        print("="*60)
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"ğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
        print(f"   æ€»ä»»åŠ¡æ•°: {validation_results['total_tasks']}")
        print(f"   æœ‰å‰ç½®ä»»åŠ¡çš„ä»»åŠ¡æ•°: {validation_results['tasks_with_predecessors']}")
        print(f"   çº¦æŸæ»¡è¶³æ•°: {validation_results['constraint_satisfied']}")
        print(f"   çº¦æŸè¿åæ•°: {len(validation_results['constraint_violations'])}")
        
        # éªŒè¯ç»“æœ
        if validation_results["validation_passed"]:
            print(f"\nâœ… éªŒè¯ç»“æœ: æ‰€æœ‰å‰ç½®ä»»åŠ¡çº¦æŸå‡æ­£ç¡®ç”Ÿæ•ˆ")
        else:
            print(f"\nâŒ éªŒè¯ç»“æœ: å‘ç° {len(validation_results['constraint_violations'])} ä¸ªçº¦æŸè¿å")
            
            print(f"\nğŸš¨ çº¦æŸè¿åè¯¦æƒ…:")
            for i, violation in enumerate(validation_results['constraint_violations'][:5], 1):
                print(f"   {i}. {violation['description']}")
                if violation['violation_type'] == 'time_constraint_violation':
                    print(f"      ä»»åŠ¡å¼€å§‹: {violation['task_start']}")
                    print(f"      å‰ç½®ä»»åŠ¡ç»“æŸ: {violation['predecessor_end']}")
        
        # ä¾èµ–å…³ç³»åˆ†æ
        print(f"\nğŸ“ˆ ä¾èµ–å…³ç³»åˆ†æ:")
        print(f"   ä¾èµ–æ¨¡å¼åˆ†å¸ƒ:")
        for pred_count, task_count in analysis["dependency_patterns"].items():
            print(f"     {pred_count} ä¸ªå‰ç½®ä»»åŠ¡: {task_count} ä¸ªä»»åŠ¡")
        
        print(f"   å¤æ‚åº¦æŒ‡æ ‡:")
        metrics = analysis["complexity_metrics"]
        print(f"     æœ€å¤§å‰ç½®ä»»åŠ¡æ•°: {metrics['max_predecessors_per_task']}")
        print(f"     å¹³å‡å‰ç½®ä»»åŠ¡æ•°: {metrics['average_predecessors_per_task']}")
        print(f"     æ€»ä¾èµ–å…³ç³»æ•°: {metrics['total_dependency_relationships']}")
        
        print(f"   å…³é”®è·¯å¾„åˆ†æ:")
        critical = analysis["critical_path_analysis"]
        print(f"     å…³é”®è·¯å¾„ä»»åŠ¡æ•°: {critical['total_critical_tasks']}")
        print(f"     å…³é”®è·¯å¾„æ¯”ä¾‹: {critical['critical_task_ratio']:.1%}")


def main():
    """ä¸»å‡½æ•°"""
    # æŸ¥æ‰¾æœ€æ–°çš„æ±‚è§£ç»“æœæ–‡ä»¶
    output_dir = os.path.join(os.path.dirname(__file__), '..', 'test_output')
    solution_files = [f for f in os.listdir(output_dir) if f.startswith('optimized_solution_') and f.endswith('.json')]
    
    if not solution_files:
        print("âŒ æœªæ‰¾åˆ°æ±‚è§£ç»“æœæ–‡ä»¶")
        return
    
    # ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶
    latest_file = max(solution_files)
    solution_path = os.path.join(output_dir, latest_file)
    
    print(f"ğŸ” éªŒè¯æ±‚è§£ç»“æœ: {latest_file}")
    
    # åˆ›å»ºéªŒè¯å™¨
    validator = DependencyConstraintValidator(solution_path)
    
    # åŠ è½½æ±‚è§£ç»“æœ
    if not validator.load_solution():
        return
    
    # éªŒè¯å‰ç½®ä»»åŠ¡çº¦æŸ
    validation_results = validator.validate_predecessor_constraints()
    
    # åˆ†æä¾èµ–å…³ç³»ç»“æ„
    analysis = validator.analyze_dependency_structure()
    
    # æ‰“å°æŠ¥å‘Š
    validator.print_validation_report(validation_results, analysis)


if __name__ == "__main__":
    main()
